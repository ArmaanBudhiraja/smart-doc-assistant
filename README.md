# ğŸ“„ ThinkPDF 
### Chat with your documents. Instantly.

ThinkPDF is an AI-powered **Retrieval-Augmented Generation (RAG)** application that allows users to upload PDF documents and ask natural language questions about them. The system generates accurate, context-aware answers grounded strictly in the content of the uploaded document.

The application is built using a **local LLM (LLaMA 3 8B)**, ensuring privacy, offline capability, and full control over data â€” with no reliance on external AI APIs.

---

## âœ¨ Features

- ğŸ“¤ **PDF Upload & Text Extraction**  
  Upload text-based PDF files and automatically extract their content.

- ğŸ§  **Context-Aware Question Answering (RAG)**  
  Answers are generated using only the retrieved document context, reducing hallucinations.

- ğŸ” **Source Grounding**  
  Each answer is backed by relevant chunks from the original document.

- ğŸ’¬ **ChatGPT-style Conversational UI**  
  Multi-turn chat interface with preserved conversation history.

- ğŸ§© **Local LLM (LLaMA 3 8B)**  
  Runs entirely on local infrastructure â€” no OpenAI or cloud dependency.

- ğŸ¨ **Modern Two-Column UI**  
  Clean interface with document metadata on the left and chat on the right.

---

## ğŸ—ï¸ System Architecture

Frontend (Next.js)
â”‚
â”œâ”€â”€ PDF Upload
â”œâ”€â”€ Chat UI
â”‚
â””â”€â”€ API Calls
      â†“
Backend (FastAPI)
â”‚
â”œâ”€â”€ PDF Ingestion
â”œâ”€â”€ Text Chunking
â”œâ”€â”€ Embeddings (Sentence Transformers)
â”œâ”€â”€ Vector Store (FAISS)
â””â”€â”€ LLaMA 3 (Answer Generation)

---

## ğŸ§  Tech Stack

### Frontend
- Next.js (App Router)
- React + TypeScript
- Custom CSS
- Lucide Icons

### Backend
- FastAPI
- SentenceTransformers
- FAISS (Vector Database)
- LLaMA 3 8B (Local Inference)

### ML / NLP
- Retrieval-Augmented Generation (RAG)
- Semantic Search
- Embedding-based Similarity Matching

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/ArmaanBudhiraja/smart-doc-assistant.git
cd smart-doc-assistant
```

### 2ï¸âƒ£To download and run Llama3 8B 
```bash
brew install ollama
brew services start ollama 
ollama pull llama3:8b
```

### 3ï¸âƒ£ Backend Setup

```bash
cd backend
pip install -r requirements.txt
```


uvicorn main:app --reload
